{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598531914256
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, choice\n",
    "from azureml.core.dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worspace and experiment\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "experiment_name = 'hyperdrive-experiment'\n",
    "#project_folder = './hyperdrive-project'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create compute cluster\n",
    "\n",
    "compute_cluster_name = \"alpha\"\n",
    "\n",
    "try:\n",
    "    compute_cluster = ComputeTarget(workspace=ws, name=compute_cluster_name)\n",
    "    print(\"Found existing cluster, please use it.\")\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\n",
    "    compute_cluster = ComputeTarget.create(ws, compute_cluster_name, compute_config)\n",
    "\n",
    "compute_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "found = False\n",
    "key = \"Heart Failure Dataset\"\n",
    "description_text = \"Heart Failure Dataset for Udacity Project 3\"\n",
    "\n",
    "if key in ws.datasets.keys():\n",
    "        found = True\n",
    "        dataset = ws.datasets[key]\n",
    "\n",
    "if not found:\n",
    "        # Create AML Dataset and register it into Workspace\n",
    "        example_data = 'https://github.com/peppegili/3_Capstone_Project_ML_Engineer/blob/master/data/heart_failure_clinical_records_dataset.csv'\n",
    "        dataset = Dataset.Tabular.from_delimited_files(example_data)        \n",
    "        #Register Dataset in Workspace\n",
    "        dataset = dataset.register(workspace=ws,\n",
    "                                   name=key,\n",
    "                                   description=description_text)\n",
    "\n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Hyperdrive Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a policy\n",
    "early_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n",
    "\n",
    "# Specify parameter sampler\n",
    "param_sampling = RandomParameterSampling(\n",
    "    {\n",
    "        \"--C\": uniform(0.1, 1.0),\n",
    "        \"--max_iter\": choice(25, 50, 100, 150)\n",
    "    }\n",
    ")\n",
    "\n",
    "# if \"training\" not in os.listdir():\n",
    "#     os.mkdir(\"./training\")\n",
    "\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "estimator = SKLearn(source_directory=\".\", compute_target=compute_cluster, entry_script=\"train.py\")\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_run_config = HyperDriveConfig(estimator=estimator,\n",
    "                                         hyperparameter_sampling=param_sampling,\n",
    "                                         policy=early_termination_policy,\n",
    "                                         primary_metric_name=\"Accuracy\",\n",
    "                                         primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                         max_total_runs=20,\n",
    "                                         max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598544897941
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit the experiment\n",
    "hdr = exp.submit(hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546648408
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(hdr).show()\n",
    "hdr.wait_for_completion(show_output=True)\n",
    "\n",
    "assert(hdr.get_status() == \"Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546650307
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_run_hdr = hdr.get_best_run_by_primary_metric()\n",
    "best_run_metrics_hdr = best_run_hdr.get_metrics()\n",
    "best_params_hdr = best_run_hdr.get_details()['runDefinition']['arguments']\n",
    "\n",
    "print(\"\\n\")\n",
    "print('Best run ID: ', best_run_hdr.id)\n",
    "print('Best run Accuracy: ', best_run_metrics_hdr['Accuracy'])\n",
    "print('Metrics: ', best_run_metrics_hdr)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(best_run_hdr.get_file_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546657829
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "joblib.dump(best_params_hdr, filename='outputs/best_model_hyperdrive.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
